{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null hypothesis- one categorical\n",
    "# from scipy import stats\n",
    "\n",
    "# F, p = stats.f_oneway(red_wine[red_wine['quality_label'] == 'low']['alcohol'],\n",
    "# red_wine[red_wine['quality_label'] == 'medium']['alcohol'],\n",
    "# red_wine[red_wine['quality_label'] == 'high']['alcohol'])\n",
    "# print('ANOVA test for mean alcohol levels across wine samples with different quality ratings')\n",
    "# print('F Statistic:', F, '\\tp-value:', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparatrion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_wine_heatmap = pd.read_csv('winequality-white.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_wine_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_wine_heatmap.drop_duplicates(inplace=True)\n",
    "white_wine_heatmap.reset_index(inplace=True)\n",
    "white_wine_heatmap.drop(columns='index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3961 entries, 0 to 3960\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         3961 non-null   float64\n",
      " 1   volatile acidity      3961 non-null   float64\n",
      " 2   citric acid           3961 non-null   float64\n",
      " 3   residual sugar        3961 non-null   float64\n",
      " 4   chlorides             3961 non-null   float64\n",
      " 5   free sulfur dioxide   3961 non-null   float64\n",
      " 6   total sulfur dioxide  3961 non-null   float64\n",
      " 7   density               3961 non-null   float64\n",
      " 8   pH                    3961 non-null   float64\n",
      " 9   sulphates             3961 non-null   float64\n",
      " 10  alcohol               3961 non-null   float64\n",
      " 11  quality               3961 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 371.5 KB\n"
     ]
    }
   ],
   "source": [
    "white_wine_heatmap.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add quality label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are creating a new column called \"quality_label\", we define a range and associate that range with a label\n",
    "white_wine_heatmap['quality label'] = white_wine_heatmap['quality'].apply(lambda value: 'low'\n",
    "if value <= 5 else 'medium'\n",
    "if value <= 7 else 'high')\n",
    "\n",
    "# here we are transforming these labels into categrical data type (specific to pandas) instead of simple string\n",
    "white_wine_heatmap['quality label'] = pd.Categorical(white_wine_heatmap['quality label'],\n",
    "categories=['low', 'medium', 'high'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hypothesis check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova_tests2(df):  \n",
    "    \n",
    "    features = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "    \n",
    "    for feature in features:\n",
    "        F, p = stats.f_oneway(\n",
    "            df[df['quality label'] == 'low'][feature],\n",
    "            df[df['quality label'] == 'medium'][feature],\n",
    "            df[df['quality label'] == 'high'][feature]\n",
    "        )\n",
    "        if p > 0.05:\n",
    "         print(f\"ANOVA test for mean {feature} across wine samples with different quality ratings\")\n",
    "         print('F Statistic:', F, '\\tp-value:', p)\n",
    "        else:\n",
    "         print(\"there is correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there is correlation\n",
      "there is correlation\n",
      "ANOVA test for mean citric acid across wine samples with different quality ratings\n",
      "F Statistic: 0.24868681586895755 \tp-value: 0.7798363477964527\n",
      "there is correlation\n",
      "there is correlation\n",
      "ANOVA test for mean free sulfur dioxide across wine samples with different quality ratings\n",
      "F Statistic: 0.11569157788750334 \tp-value: 0.8907529199895233\n",
      "there is correlation\n",
      "there is correlation\n",
      "there is correlation\n",
      "there is correlation\n",
      "there is correlation\n"
     ]
    }
   ],
   "source": [
    "anova_tests2(white_wine_heatmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing wine type to 0 and 1\n",
    "wine1=white_wine_heatmap.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine1.drop(columns='citric acid', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine1.drop(columns='free sulfur dioxide', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoding and dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# Create an instance of OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder(categories=[['low', 'medium', 'high']])\n",
    "wine1['NumericalLabels'] = ordinal_encoder.fit_transform(wine1[['quality label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine1.drop(columns='quality', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine1.drop(columns='quality label', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "divide into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importm library for dicidint the dataset into two \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>NumericalLabels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  residual sugar  chlorides  \\\n",
       "0            7.0              0.27            20.7      0.045   \n",
       "\n",
       "   total sulfur dioxide  density   pH  sulphates  alcohol  NumericalLabels  \n",
       "0                 170.0    1.001  3.0       0.45      8.8              1.0  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine2=wine1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine2.drop(columns='NumericalLabels', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=wine2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = wine1['NumericalLabels']  # --> what you're trying to predict\n",
    "  # --> the features we will keep to build our model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3961, 9)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3961,)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 9) (793, 9) (3168,) (793,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution Before SMOTE (Training Set): Counter({1.0: 1987, 0.0: 1074, 2.0: 107})\n"
     ]
    }
   ],
   "source": [
    "# Display class distribution before oversampling\n",
    "print(\"Class Distribution Before SMOTE (Training Set):\", Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE for oversampling only on the training set\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution After SMOTE (Training Set): Counter({1.0: 1987, 0.0: 1987, 2.0: 1987})\n"
     ]
    }
   ],
   "source": [
    "# Display class distribution after oversampling\n",
    "print(\"Class Distribution After SMOTE (Training Set):\", Counter(y_train_resampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model= RandomForestClassifier(n_estimators= 100, criterion='entropy', random_state=445)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=445)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=445)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', random_state=445)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_model.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2= RF_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 1., 2., 1., 0., 1., 2., 1., 1., 0., 2.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 2., 1., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 0., 1., 1., 0., 2., 1., 0., 1., 2., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 0., 2., 1., 0., 0., 1., 0., 1., 2., 1., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 2., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 2., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 0., 1., 2., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       2., 2., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 2., 1.,\n",
       "       0., 1., 0., 2., 1., 0., 1., 1., 0., 2., 2., 0., 1., 0., 0., 0., 2.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 2., 0., 1., 1., 0., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 2., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 2., 1., 1., 1., 1., 0., 1., 0., 0., 2., 0., 1., 2., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 0., 2., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "       1., 0., 2., 2., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 2., 1., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 2., 1., 0., 1., 0., 1., 2., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 2., 1.,\n",
       "       1., 2., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 2., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 2., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 2., 1., 0., 0., 2., 1., 1., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 2., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 2., 0., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 2., 1., 0.,\n",
       "       0., 1., 1., 0., 1., 2., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 2., 1., 1., 2.,\n",
       "       0., 1., 1., 1., 2., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       2., 2., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 2., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 2., 0., 1., 0., 1., 0., 1., 2., 0., 0., 0., 0.,\n",
       "       2., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 1., 2., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 2., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 2., 0., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 2., 1., 0., 1., 1., 0., 1., 1., 1., 2., 1.,\n",
       "       1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6620428751576293"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc=accuracy_score(y_test, preds2)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6620428751576293\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.70      0.65       274\n",
      "         1.0       0.77      0.66      0.71       490\n",
      "         2.0       0.17      0.31      0.22        29\n",
      "\n",
      "    accuracy                           0.66       793\n",
      "   macro avg       0.51      0.56      0.53       793\n",
      "weighted avg       0.69      0.66      0.67       793\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[191  79   4]\n",
      " [124 325  41]\n",
      " [  1  19   9]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, preds2)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, preds2))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, preds2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st try no scaling or oversampling\n",
    "Accuracy: 0.7301387137452712\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.67      0.63      0.65       274\n",
    "         1.0       0.76      0.83      0.79       490\n",
    "         2.0       0.50      0.03      0.06        29\n",
    "\n",
    "    accuracy                           0.73       793\n",
    "   macro avg       0.64      0.50      0.50       793\n",
    "weighted avg       0.72      0.73      0.72       793\n",
    "\n",
    "\n",
    "Confusion Matrix:\n",
    "[[172 102   0]\n",
    " [ 83 406   1]\n",
    " [  0  28   1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd try oversampling:\n",
    "Accuracy: 0.669609079445145\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.61      0.70      0.65       274\n",
    "         1.0       0.77      0.68      0.72       490\n",
    "         2.0       0.12      0.17      0.14        29\n",
    "\n",
    "    accuracy                           0.67       793\n",
    "   macro avg       0.50      0.52      0.50       793\n",
    "weighted avg       0.69      0.67      0.68       793\n",
    "\n",
    "\n",
    "Confusion Matrix:\n",
    "[[193  79   2]\n",
    " [121 333  36]\n",
    " [  2  22   5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3rd try removed irrelevant columns:\n",
    "Accuracy: 0.6620428751576293\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.60      0.70      0.65       274\n",
    "         1.0       0.77      0.66      0.71       490\n",
    "         2.0       0.17      0.31      0.22        29\n",
    "\n",
    "    accuracy                           0.66       793\n",
    "   macro avg       0.51      0.56      0.53       793\n",
    "weighted avg       0.69      0.66      0.67       793\n",
    "\n",
    "\n",
    "Confusion Matrix:\n",
    "[[191  79   4]\n",
    " [124 325  41]\n",
    " [  1  19   9]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train1 = scaler.fit_transform(X_train_resampled)\n",
    "X_test1 = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 3  # You can adjust this value based on your problem\n",
    "knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "knn_model.fit(X_train1, y_train_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_model.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.562421185372005\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.66      0.60       274\n",
      "         1.0       0.74      0.52      0.61       490\n",
      "         2.0       0.09      0.38      0.15        29\n",
      "\n",
      "    accuracy                           0.56       793\n",
      "   macro avg       0.46      0.52      0.45       793\n",
      "weighted avg       0.65      0.56      0.59       793\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[180  76  18]\n",
      " [147 255  88]\n",
      " [  4  14  11]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st try\n",
    "Accuracy: 0.6973518284993695\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.62      0.62      0.62       274\n",
    "         1.0       0.75      0.77      0.76       490\n",
    "         2.0       0.25      0.14      0.18        29\n",
    "\n",
    "    accuracy                           0.70       793\n",
    "   macro avg       0.54      0.51      0.52       793\n",
    "weighted avg       0.69      0.70      0.69       793\n",
    "\n",
    "\n",
    "Confusion Matrix:\n",
    "[[171 101   2]\n",
    " [102 378  10]\n",
    " [  2  23   4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd try:\n",
    "Accuracy: 0.6015132408575031\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.59      0.74      0.66       274\n",
    "         1.0       0.78      0.54      0.64       490\n",
    "         2.0       0.07      0.24      0.10        29\n",
    "\n",
    "    accuracy                           0.60       793\n",
    "   macro avg       0.48      0.51      0.47       793\n",
    "weighted avg       0.69      0.60      0.63       793\n",
    "\n",
    "\n",
    "Confusion Matrix:\n",
    "[[204  59  11]\n",
    " [136 266  88]\n",
    " [  5  17   7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3rd try:\n",
    "\n",
    "Accuracy: 0.562421185372005\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.54      0.66      0.60       274\n",
    "         1.0       0.74      0.52      0.61       490\n",
    "         2.0       0.09      0.38      0.15        29\n",
    "\n",
    "    accuracy                           0.56       793\n",
    "   macro avg       0.46      0.52      0.45       793\n",
    "weighted avg       0.65      0.56      0.59       793\n",
    "\n",
    "\n",
    "Confusion Matrix:\n",
    "[[180  76  18]\n",
    " [147 255  88]\n",
    " [  4  14  11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4=wine2\n",
    "y4 = wine1['NumericalLabels']  # --> what you're trying to predict\n",
    "  # --> the features we will keep to build our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardize the features (important for SVM)\n",
    "scaler = StandardScaler()\n",
    "X4_train = scaler.fit_transform(X_train_resampled)\n",
    "X4_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVM classifier\n",
    "svm_classifier = SVC(kernel='linear', C=1.0, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Train the SVM classifier\n",
    "svm_classifier.fit(X4_train, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "prediction4 = svm_classifier.predict(X4_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.51\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.74      0.64       274\n",
      "         1.0       0.73      0.37      0.49       490\n",
      "         2.0       0.11      0.69      0.18        29\n",
      "\n",
      "    accuracy                           0.51       793\n",
      "   macro avg       0.47      0.60      0.44       793\n",
      "weighted avg       0.65      0.51      0.53       793\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[202  56  16]\n",
      " [158 179 153]\n",
      " [  0   9  20]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the classifier\n",
    "accuracy4 = accuracy_score(y_test, prediction4)\n",
    "report4 = classification_report(y_test, prediction4)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy4:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", report4)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, prediction4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st try:\n",
    "Accuracy: 0.70\n",
    "\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.64      0.53      0.58       274\n",
    "         1.0       0.72      0.83      0.77       490\n",
    "         2.0       0.00      0.00      0.00        29\n",
    "\n",
    "    accuracy                           0.70       793\n",
    "   macro avg       0.45      0.45      0.45       793\n",
    "weighted avg       0.67      0.70      0.68       793\n",
    "\n",
    "\n",
    "Confusion Matrix:\n",
    "[[145 129   0]\n",
    " [ 82 408   0]\n",
    " [  0  29   0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd try:\n",
    "Accuracy: 0.52\n",
    "\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.56      0.73      0.64       274\n",
    "         1.0       0.76      0.38      0.51       490\n",
    "         2.0       0.11      0.72      0.19        29\n",
    "\n",
    "    accuracy                           0.52       793\n",
    "   macro avg       0.48      0.61      0.45       793\n",
    "weighted avg       0.67      0.52      0.54       793\n",
    "\n",
    "\n",
    "Confusion Matrix:\n",
    "[[201  52  21]\n",
    " [156 188 146]\n",
    " [  0   8  21]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3rd try:\n",
    "Accuracy: 0.51\n",
    "\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.56      0.74      0.64       274\n",
    "         1.0       0.73      0.37      0.49       490\n",
    "         2.0       0.11      0.69      0.18        29\n",
    "\n",
    "    accuracy                           0.51       793\n",
    "   macro avg       0.47      0.60      0.44       793\n",
    "weighted avg       0.65      0.51      0.53       793\n",
    "\n",
    "\n",
    "Confusion Matrix:\n",
    "[[202  56  16]\n",
    " [158 179 153]\n",
    " [  0   9  20]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
